{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import libraries\n",
    "# 2. Image -> OCR, generate a csv with all words\n",
    "# 3. OCR, define specified words with coordinates\n",
    "# 4. Apply white boxes to coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Cell 1 Imports & helpers\n",
    "from pathlib import Path\n",
    "import json, random, time, csv\n",
    "from faker import Faker\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pytesseract\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import ollama\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import difflib\n",
    "import re\n",
    "\n",
    "INPUT_DIR = Path(\"input_images\")\n",
    "OUTPUT_DIR = Path(\"output_statements\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "fake = Faker(\"en_US\")\n",
    "FONT = ImageFont.truetype(\"arial.ttf\", 10)\n",
    "pytesseract.pytesseract.tesseract_cmd = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 1: Cell 1 Imports & helpers\n",
    "from pathlib import Path\n",
    "import json, random, time, csv\n",
    "from faker import Faker\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pytesseract\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import ollama\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import difflib\n",
    "import re\n",
    "import platform\n",
    "\n",
    "INPUT_DIR = Path(\"input_images\")\n",
    "OUTPUT_DIR = Path(\"output_statements\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "fake = Faker(\"en_US\")\n",
    "\n",
    "# Set font based on operating system\n",
    "if platform.system() == \"Darwin\":\n",
    "    FONT = ImageFont.truetype(\"/Library/Fonts/Arial.ttf\", 10)\n",
    "elif platform.system() == \"Windows\":\n",
    "    FONT = ImageFont.truetype(\"C:\\\\Windows\\\\Fonts\\\\arial.ttf\", 10)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported OS. Set FONT path manually.\")\n",
    "\n",
    "# Set Tesseract path based on operating system\n",
    "if platform.system() == \"Darwin\":  # macOS\n",
    "    pytesseract.pytesseract.tesseract_cmd = \"/opt/homebrew/bin/tesseract\"\n",
    "    if not Path(pytesseract.pytesseract.tesseract_cmd).exists():\n",
    "        pytesseract.pytesseract.tesseract_cmd = \"/usr/local/bin/tesseract\"\n",
    "elif platform.system() == \"Windows\":  # Windows\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "else:\n",
    "    raise ValueError(\"Unsupported operating system. Please set tesseract_cmd manually.\")\n",
    "\n",
    "if not Path(pytesseract.pytesseract.tesseract_cmd).exists():\n",
    "    print(f\"Warning: Tesseract not found at {pytesseract.pytesseract.tesseract_cmd}. Please install or adjust the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chase_highres.png for text extraction\n",
      "   • Extracting text from chase_highres.png … done.\n",
      "   • Extracted tokens: ['CHASE', '“', 'January', '1,', '2020', 'through', 'February', '23,', '2020', 'Primary', 'Account', '690783870', 'JPM', 'organ', 'Chase', 'Bank', 'NA.', 'Ohio/West', 'Virginia', 'Markets', 'POG', 'ae', '——SSSSSSS', 'Baton', 'Rouge.', 'LA', '70826-0180', 'CUSTOMER', 'SERVICE', 'INFORMATION', 'YS', 'TEE', 'TET', 'EL', 'WebSite:', 'www.Chase.com', 'Service', 'Center:', '1-800-935-9935', 'Hearing', 'Impaired:', '1-800-242-7383', 'Ldlaeaabd', 'dll', 'se', 'la!}', 'blaldaldh', 'bdbdlal', 'ParaEspand:', 'H7-2124275', 'ee', 'eusisen', 'CEA', 'el', 'KA', 'teat', 'sur', 'eles', 'International', 'Calls:', '1-713-262-1679', '—', 'Joseph', 'Cabrera', '—', '11020', 'NE', '14TH', 'AVE', '=', 'MIAMI', 'FL', '33161', '—>', '—?', 'Ee', 'ts)', '|', '—————', 'J', '—', '—', '—', '——', '—', '2', '——-', 'CHECKING', 'SUMMAR', 'INSTANCES', 'AMOUNT', 'Beginning', 'Balance', '$81,607.40', 'Deposits', 'and', 'Additions', '10', '125', '883.63', 'Checks', 'Paid', '2', '3,169.04', 'Other', 'Withdrawals', 'Fees', '&', 'Charges', '4', '15025.68', 'Ending', 'Balance', '70', '$189', '296.31', 'This', 'message', 'confirms', 'that', 'you', 'have', 'overdraft', 'protection', 'on', 'your', 'checking', 'account.', 'DEPOSITS', 'AND', 'ADDITIONS', 'DATE', 'CESCRIPTION', 'AMOUNT', '01/02', 'Deposit', '$17,120.00', '01/09', 'Deposit', '24610.00', '01/14', 'Deposit', '1142400', '01/15', 'Deposit', '1349.00', '01/21', 'Deposit', '5', '000.00', '02/21', 'Deposit', '3,120.00', '02/23', 'Deposit', '33.138.00', '02/28', 'Deposit', '18', '114.00', '02/29', 'Deposit', '6', '908.63', '02/29', 'Deposit', '5', '100.00', '———_—&——————————————', 'OO', 'eeeeeeeeeeeeeeEEEer:ErErE—r————=yEeEeuEXwlE', 'EE', 'Total', 'Deposits', 'and', 'Additions', '$125,883.63', 'Page', '1', 'of', '4']\n",
      "   • Saved extracted tokens: output_statements/extracted_chase_highres.csv\n",
      "Extracted 181 text items\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 2: Text Extraction\n",
    "def extract_text(img_path: Path):\n",
    "    print(f\"   • Extracting text from {img_path.name} …\", end=\" \", flush=True)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        text = pytesseract.image_to_string(img, config=\"--psm 6 --oem 3\")\n",
    "        # Improved tokenization: preserve numbers with commas and decimals\n",
    "        tokens = []\n",
    "        current_token = \"\"\n",
    "        for char in text:\n",
    "            if char.isspace():\n",
    "                if current_token:\n",
    "                    tokens.append(current_token)\n",
    "                    current_token = \"\"\n",
    "            elif char in [',', '.', '-'] and current_token and current_token[-1].isdigit():\n",
    "                current_token += char  # Keep commas and periods in numbers\n",
    "            elif char in [',', '.', '-', '/'] and not current_token:\n",
    "                continue  # Skip standalone delimiters\n",
    "            else:\n",
    "                current_token += char\n",
    "        if current_token:\n",
    "            tokens.append(current_token)\n",
    "\n",
    "        extracted = [token.strip() for token in tokens if token.strip()]\n",
    "        print(\"done.\")\n",
    "        print(f\"   • Extracted tokens: {extracted}\")\n",
    "        csv_path = OUTPUT_DIR / f\"extracted_{img_path.stem}.csv\"\n",
    "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"text\"])  # Header\n",
    "            for token in extracted:\n",
    "                writer.writerow([token])\n",
    "        print(f\"   • Saved extracted tokens: {csv_path}\")\n",
    "        return extracted\n",
    "    except Exception as e:\n",
    "        print(f\"error: {type(e).__name__}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_folder_extract():\n",
    "    img_files = list(INPUT_DIR.glob(\"*.jp*\")) + list(INPUT_DIR.glob(\"*.png\"))\n",
    "    if not img_files:\n",
    "        print(\"⚠️  No images found in\", INPUT_DIR.resolve())\n",
    "        return\n",
    "    for img in img_files:\n",
    "        print(f\"Processing {img.name} for text extraction\")\n",
    "        extracted = extract_text(img)\n",
    "        if not extracted:\n",
    "            print(\"No text extracted or processing failed\")\n",
    "        else:\n",
    "            print(f\"Extracted {len(extracted)} text items\")\n",
    "\n",
    "process_folder_extract()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chase_highres.png for OCR coordinate generation\n",
      "   • Found “690783870” → [1689,226,188,32]\n",
      "   • Found “joseph cabrera” → [143,678,238,33]\n",
      "   • Found “miami fl 33161” → [142,754,243,42]\n",
      "   • Found “11020 ne 14th ave” → [143,719,313,26]\n",
      "   • Found “deposit” → [386,2054,121,42]\n",
      "   • Found “deposit” → [386,2101,120,43]\n",
      "   • Found “deposit” → [386,2148,121,40]\n",
      "   • Found “deposit” → [386,2194,120,43]\n",
      "   • Found “deposit” → [386,2240,121,43]\n",
      "   • Found “deposit” → [386,2287,121,43]\n",
      "   • Found “deposit” → [386,2333,121,43]\n",
      "   • Found “deposit” → [386,2380,121,43]\n",
      "   • Found “deposit” → [386,2426,121,43]\n",
      "   • Found “deposit” → [386,2476,121,43]\n",
      "   • Found “1142400” → [1882,2152,145,27]\n",
      "   • Found “- 3,169.04” → [1294,1597,153,32]\n",
      "   • Found “1349.00” → [1900,2199,127,27]\n",
      "   • Found “$125883.63” → [1843,2532,187,34]\n",
      "   • Found “18 114.00” → [1882,2388,145,27]\n",
      "   • Found “$17,120.00” → [1861,2057,166,33]\n",
      "   • Found “- 15025.68” → [1275,1646,169,32]\n",
      "   • Found “5 100.00” → [1900,2481,127,27]\n",
      "   • Found “5 000.00” → [1900,2249,127,26]\n",
      "   • Found “125 883.63” → [1281,1541,166,31]\n",
      "   • Found “33.138.00” → [1878,2342,149,26]\n",
      "   • Found “$189 296.31” → [1261,1698,184,45]\n",
      "   • Found “24610.00” → [1878,2106,149,27]\n",
      "   • Found “6 908.63” → [1896,2435,133,39]\n",
      "   • Found “3120.00” → [1896,2295,131,27]\n",
      "   • Found “$81,607.40” → [1280,1486,165,35]\n",
      "   • Found “01/15” → [155,2199,86,27]\n",
      "   • Found “02/29” → [155,2426,83,52]\n",
      "   • Found “02/29” → [155,2476,83,43]\n",
      "   • Found “01/14” → [155,2153,86,26]\n",
      "   • Found “02/28” → [155,2380,83,43]\n",
      "   • Found “02/23” → [155,2333,86,43]\n",
      "   • Found “01/02” → [155,2059,83,27]\n",
      "   • Found “02/21” → [155,2287,80,43]\n",
      "   • Found “01/09” → [155,2106,83,27]\n",
      "   • Found “01/21” → [155,2245,80,27]\n",
      "   • Found “10” → [1029,1541,32,27]\n",
      "   • Found “2” → [1044,1597,17,27]\n",
      "   • Found “70” → [1017,1706,35,26]\n",
      "   • Found “4” → [1044,1647,20,25]\n",
      "   • Saved 44 coords → white_box_coords_chase_highres.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 – OCR-driven coordinates using multiple lists\n",
    "\n",
    "from pathlib import Path\n",
    "import json, re\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# ── 1.  Define your individual lists ─────────────────────────────\n",
    "chase_header = {\"JPM organ Chase Bank NA. Ohio/West Virginia Markets pS amas ees\"}\n",
    "\n",
    "date_header  = {\"January 1, 2020 through February 29, 2020\"}\n",
    "\n",
    "account_number     = {\"690783870\"}\n",
    "customer_mailing   = {\"joseph cabrera\", \"miami fl 33161\", \"11020 ne 14th ave\"}\n",
    "\n",
    "checking_summary_instances = {\"10\", \"2\", \"4\", \"70\"}\n",
    "\n",
    "checking_summary_amount = {\n",
    "    \"$81,607.40\", \"125 883.63\", \"- 3,169.04\", \"- 15025.68\", \"$189 296.31\"\n",
    "}\n",
    "\n",
    "deposit_additions_amounts = {\n",
    "    \"$17,120.00\", \"24610.00\", \"1142400\", \"1349.00\", \"5 000.00\", \"3120.00\",\n",
    "    \"33.138.00\", \"18 114.00\", \"6 908.63\", \"5 100.00\", \"$125883.63\"\n",
    "}\n",
    "deposit_additions_description = {\"deposit\"}\n",
    "deposit_additions_date        = {\n",
    "    \"01/02\", \"01/09\", \"01/14\", \"01/15\", \"01/21\",\n",
    "    \"02/21\", \"02/23\", \"02/28\", \"02/29\"\n",
    "}\n",
    "\n",
    "# ── 2.  Bundle them into categories ──────────────────────────────\n",
    "WHITE_BOX_PHRASES: dict[str, set[str]] = {\n",
    "    \"sensitive_customer\": customer_mailing | account_number,\n",
    "    \"transaction_desc\"  : deposit_additions_description,\n",
    "    \"amount\"            : checking_summary_amount | deposit_additions_amounts,\n",
    "    \"date\"              : deposit_additions_date,\n",
    "    \"instance\"          : checking_summary_instances,\n",
    "}\n",
    "\n",
    "# ── utility: word-level OCR boxes ────────────────────────────────\n",
    "def ocr_word_boxes(img_path: Path):\n",
    "    img  = Image.open(img_path).convert(\"RGB\")\n",
    "    data = pytesseract.image_to_data(\n",
    "        img, output_type=pytesseract.Output.DICT, config=\"--psm 6 --oem 3\"\n",
    "    )\n",
    "    words = []\n",
    "    for i, txt in enumerate(data[\"text\"]):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        words.append({\n",
    "            \"text\": txt,\n",
    "            \"left\": data[\"left\"][i],\n",
    "            \"top\":  data[\"top\"][i],\n",
    "            \"right\": data[\"left\"][i] + data[\"width\"][i],\n",
    "            \"bottom\": data[\"top\"][i] + data[\"height\"][i],\n",
    "            \"width\":  data[\"width\"][i],\n",
    "            \"height\": data[\"height\"][i],\n",
    "        })\n",
    "    return words, img.size\n",
    "\n",
    "# helper: canonicalise text for matching\n",
    "def canon(txt: str) -> str:\n",
    "    txt = txt.lower().strip()\n",
    "    txt = re.sub(r'\\s+', ' ', txt)\n",
    "    return txt.replace('$', '').replace(',', '').replace('.', '')\n",
    "\n",
    "# ── main coordinate builder ──────────────────────────────────────\n",
    "def make_coords(img_path: Path):\n",
    "    words, _ = ocr_word_boxes(img_path)\n",
    "    coords   = []\n",
    "\n",
    "    # 1️⃣ locate “Instances” header\n",
    "    inst_col = None\n",
    "    for w in words:\n",
    "        if canon(w[\"text\"]) in {\"instances\", \"instance\", \"lnstances\", \"lntances\"}:\n",
    "            inst_col = (w[\"left\"], w[\"right\"])\n",
    "            break\n",
    "\n",
    "    # 2️⃣ normal matching pass\n",
    "    for category, phrase_set in WHITE_BOX_PHRASES.items():\n",
    "        for phrase in phrase_set:\n",
    "            tokens = [canon(tok) for tok in phrase.split()]\n",
    "            n = len(tokens)\n",
    "            i = 0\n",
    "            while i <= len(words) - n:\n",
    "                if [canon(w[\"text\"]) for w in words[i:i+n]] == tokens:\n",
    "                    left   = min(w[\"left\"]   for w in words[i:i+n])\n",
    "                    top    = min(w[\"top\"]    for w in words[i:i+n])\n",
    "                    right  = max(w[\"right\"]  for w in words[i:i+n])\n",
    "                    bottom = max(w[\"bottom\"] for w in words[i:i+n])\n",
    "\n",
    "                    # filter “instance” hits by column (if header found)\n",
    "                    if category == \"instance\" and inst_col:\n",
    "                        x_mid = (left + right) // 2\n",
    "                        col_left, col_right = inst_col\n",
    "                        margin = 5           # ← original narrow margin\n",
    "                        if not (col_left - margin <= x_mid <= col_right + margin):\n",
    "                            i += 1\n",
    "                            continue\n",
    "\n",
    "                    coords.append({\n",
    "                        \"text\": phrase,\n",
    "                        \"category\": category,\n",
    "                        \"x\": left,\n",
    "                        \"y\": top,\n",
    "                        \"width\":  right - left,\n",
    "                        \"height\": bottom - top,\n",
    "                    })\n",
    "                    print(f\"   • Found “{phrase}” → [{left},{top},{right-left},{bottom-top}]\")\n",
    "                    i += n\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "    out_json = OUTPUT_DIR / f\"white_box_coords_{img_path.stem}.json\"\n",
    "    out_json.write_text(json.dumps(coords, indent=2))\n",
    "    print(f\"   • Saved {len(coords)} coords → {out_json.name}\")\n",
    "    return coords\n",
    "\n",
    "# convenience runner\n",
    "def process_white_box_terms():\n",
    "    img_path = INPUT_DIR / \"chase_highres.png\"\n",
    "    if not img_path.exists():\n",
    "        img_path = INPUT_DIR / \"chase_highres.jpg\"\n",
    "    if not img_path.exists():\n",
    "        print(\"⚠️  chase_highres image not found\"); return\n",
    "\n",
    "    print(f\"Processing {img_path.name} for OCR coordinate generation\")\n",
    "    make_coords(img_path)\n",
    "\n",
    "process_white_box_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chase_highres.png for red box preview\n",
      "   • Applied red box preview to '690783870' at (1689, 226) with size (188, 32)\n",
      "   • Applied red box preview to 'joseph cabrera' at (143, 678) with size (238, 33)\n",
      "   • Applied red box preview to 'miami fl 33161' at (142, 754) with size (243, 42)\n",
      "   • Applied red box preview to '11020 ne 14th ave' at (143, 719) with size (313, 26)\n",
      "   • Applied red box preview to 'deposit' at (386, 2054) with size (121, 42)\n",
      "   • Applied red box preview to 'deposit' at (386, 2101) with size (120, 43)\n",
      "   • Applied red box preview to 'deposit' at (386, 2148) with size (121, 40)\n",
      "   • Applied red box preview to 'deposit' at (386, 2194) with size (120, 43)\n",
      "   • Applied red box preview to 'deposit' at (386, 2240) with size (121, 43)\n",
      "   • Applied red box preview to 'deposit' at (386, 2287) with size (121, 43)\n",
      "   • Applied red box preview to 'deposit' at (386, 2333) with size (121, 43)\n",
      "   • Applied red box preview to 'deposit' at (386, 2380) with size (121, 43)\n",
      "   • Applied red box preview to 'deposit' at (386, 2426) with size (121, 43)\n",
      "   • Applied red box preview to 'deposit' at (386, 2476) with size (121, 43)\n",
      "   • Applied red box preview to '1142400' at (1882, 2152) with size (145, 27)\n",
      "   • Applied red box preview to '- 3,169.04' at (1294, 1597) with size (153, 32)\n",
      "   • Applied red box preview to '1349.00' at (1900, 2199) with size (127, 27)\n",
      "   • Applied red box preview to '$125883.63' at (1843, 2532) with size (187, 34)\n",
      "   • Applied red box preview to '18 114.00' at (1882, 2388) with size (145, 27)\n",
      "   • Applied red box preview to '$17,120.00' at (1861, 2057) with size (166, 33)\n",
      "   • Applied red box preview to '- 15025.68' at (1275, 1646) with size (169, 32)\n",
      "   • Applied red box preview to '5 100.00' at (1900, 2481) with size (127, 27)\n",
      "   • Applied red box preview to '5 000.00' at (1900, 2249) with size (127, 26)\n",
      "   • Applied red box preview to '125 883.63' at (1281, 1541) with size (166, 31)\n",
      "   • Applied red box preview to '33.138.00' at (1878, 2342) with size (149, 26)\n",
      "   • Applied red box preview to '$189 296.31' at (1261, 1698) with size (184, 45)\n",
      "   • Applied red box preview to '24610.00' at (1878, 2106) with size (149, 27)\n",
      "   • Applied red box preview to '6 908.63' at (1896, 2435) with size (133, 39)\n",
      "   • Applied red box preview to '3120.00' at (1896, 2295) with size (131, 27)\n",
      "   • Applied red box preview to '$81,607.40' at (1280, 1486) with size (165, 35)\n",
      "   • Applied red box preview to '01/15' at (155, 2199) with size (86, 27)\n",
      "   • Applied red box preview to '02/29' at (155, 2426) with size (83, 52)\n",
      "   • Applied red box preview to '02/29' at (155, 2476) with size (83, 43)\n",
      "   • Applied red box preview to '01/14' at (155, 2153) with size (86, 26)\n",
      "   • Applied red box preview to '02/28' at (155, 2380) with size (83, 43)\n",
      "   • Applied red box preview to '02/23' at (155, 2333) with size (86, 43)\n",
      "   • Applied red box preview to '01/02' at (155, 2059) with size (83, 27)\n",
      "   • Applied red box preview to '02/21' at (155, 2287) with size (80, 43)\n",
      "   • Applied red box preview to '01/09' at (155, 2106) with size (83, 27)\n",
      "   • Applied red box preview to '01/21' at (155, 2245) with size (80, 27)\n",
      "   • Applied red box preview to '10' at (1029, 1541) with size (32, 27)\n",
      "   • Applied red box preview to '2' at (1044, 1597) with size (17, 27)\n",
      "   • Applied red box preview to '70' at (1017, 1706) with size (35, 26)\n",
      "   • Applied red box preview to '4' at (1044, 1647) with size (20, 25)\n",
      "   • 44 red boxes applied → chase_highres_preview.png\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 4a: Generate Red Box Preview\n",
    "KEEP_CATEGORIES = {\"sensitive_customer\", \"transaction_desc\", \"amount\", \"date\", \"instance\"}\n",
    "NEVER_BLANK = set()\n",
    "\n",
    "def apply_red_box_preview(img_path, coord_path):\n",
    "    coords = json.loads(coord_path.read_text())\n",
    "    if not coords:\n",
    "        print(\"Error: No coordinates found in JSON file\")\n",
    "        return None\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    image_width, image_height = img.size\n",
    "\n",
    "    boxes = 0\n",
    "    for c in coords:\n",
    "        cat = c.get(\"category\")\n",
    "        text = c.get(\"text\", \"\").lower()\n",
    "\n",
    "        if cat not in KEEP_CATEGORIES:\n",
    "            continue\n",
    "        if any(kw in text for kw in NEVER_BLANK):\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = map(int, (c[\"x\"], c[\"y\"], c[\"width\"], c[\"height\"]))\n",
    "\n",
    "        inset = 1\n",
    "        x1 = max(0, x + inset)\n",
    "        y1 = max(0, y + inset)\n",
    "        x2 = min(image_width - 1, x + w - inset)\n",
    "        y2 = min(image_height - 1, y + h - inset)\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)  # Red outline for preview\n",
    "        boxes += 1\n",
    "        print(f\"   • Applied red box preview to '{c.get('text', 'unknown')}' at ({x}, {y}) with size ({w}, {h})\")\n",
    "\n",
    "    out = OUTPUT_DIR / f\"{img_path.stem}_preview.png\"\n",
    "    img.save(out, dpi=(300, 300))\n",
    "    print(f\"   • {boxes} red boxes applied → {out.name}\")\n",
    "    return out\n",
    "\n",
    "def process_red_box_preview():\n",
    "    img_path = INPUT_DIR / \"chase_highres.png\"\n",
    "    if not img_path.exists():\n",
    "        img_path = INPUT_DIR / \"chase_highres.jpg\"\n",
    "    if not img_path.exists():\n",
    "        print(f\"Error: Image not found at {img_path}\")\n",
    "        return\n",
    "    coord_path = OUTPUT_DIR / f\"white_box_coords_{img_path.stem}.json\"\n",
    "    if not coord_path.exists():\n",
    "        print(f\"Error: Coordinate file not found at {coord_path}\")\n",
    "        return\n",
    "    print(f\"Processing {img_path.name} for red box preview\")\n",
    "    apply_red_box_preview(img_path, coord_path)\n",
    "\n",
    "process_red_box_preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chase_highres.png for white-box application\n",
      "   • Applied white box to '690783870' at (1689, 226) with size (188, 32)\n",
      "   • Applied white box to 'joseph cabrera' at (143, 678) with size (238, 33)\n",
      "   • Applied white box to 'miami fl 33161' at (142, 754) with size (243, 42)\n",
      "   • Applied white box to '11020 ne 14th ave' at (143, 719) with size (313, 26)\n",
      "   • Applied white box to 'deposit' at (386, 2054) with size (121, 42)\n",
      "   • Applied white box to 'deposit' at (386, 2101) with size (120, 43)\n",
      "   • Applied white box to 'deposit' at (386, 2148) with size (121, 40)\n",
      "   • Applied white box to 'deposit' at (386, 2194) with size (120, 43)\n",
      "   • Applied white box to 'deposit' at (386, 2240) with size (121, 43)\n",
      "   • Applied white box to 'deposit' at (386, 2287) with size (121, 43)\n",
      "   • Applied white box to 'deposit' at (386, 2333) with size (121, 43)\n",
      "   • Applied white box to 'deposit' at (386, 2380) with size (121, 43)\n",
      "   • Applied white box to 'deposit' at (386, 2426) with size (121, 43)\n",
      "   • Applied white box to 'deposit' at (386, 2476) with size (121, 43)\n",
      "   • Applied white box to '1142400' at (1882, 2152) with size (145, 27)\n",
      "   • Applied white box to '- 3,169.04' at (1294, 1597) with size (153, 32)\n",
      "   • Applied white box to '1349.00' at (1900, 2199) with size (127, 27)\n",
      "   • Applied white box to '$125883.63' at (1843, 2532) with size (187, 34)\n",
      "   • Applied white box to '18 114.00' at (1882, 2388) with size (145, 27)\n",
      "   • Applied white box to '$17,120.00' at (1861, 2057) with size (166, 33)\n",
      "   • Applied white box to '- 15025.68' at (1275, 1646) with size (169, 32)\n",
      "   • Applied white box to '5 100.00' at (1900, 2481) with size (127, 27)\n",
      "   • Applied white box to '5 000.00' at (1900, 2249) with size (127, 26)\n",
      "   • Applied white box to '125 883.63' at (1281, 1541) with size (166, 31)\n",
      "   • Applied white box to '33.138.00' at (1878, 2342) with size (149, 26)\n",
      "   • Applied white box to '$189 296.31' at (1261, 1698) with size (184, 45)\n",
      "   • Applied white box to '24610.00' at (1878, 2106) with size (149, 27)\n",
      "   • Applied white box to '6 908.63' at (1896, 2435) with size (133, 39)\n",
      "   • Applied white box to '3120.00' at (1896, 2295) with size (131, 27)\n",
      "   • Applied white box to '$81,607.40' at (1280, 1486) with size (165, 35)\n",
      "   • Applied white box to '01/15' at (155, 2199) with size (86, 27)\n",
      "   • Applied white box to '02/29' at (155, 2426) with size (83, 52)\n",
      "   • Applied white box to '02/29' at (155, 2476) with size (83, 43)\n",
      "   • Applied white box to '01/14' at (155, 2153) with size (86, 26)\n",
      "   • Applied white box to '02/28' at (155, 2380) with size (83, 43)\n",
      "   • Applied white box to '02/23' at (155, 2333) with size (86, 43)\n",
      "   • Applied white box to '01/02' at (155, 2059) with size (83, 27)\n",
      "   • Applied white box to '02/21' at (155, 2287) with size (80, 43)\n",
      "   • Applied white box to '01/09' at (155, 2106) with size (83, 27)\n",
      "   • Applied white box to '01/21' at (155, 2245) with size (80, 27)\n",
      "   • Applied white box to '10' at (1029, 1541) with size (32, 27)\n",
      "   • Applied white box to '2' at (1044, 1597) with size (17, 27)\n",
      "   • Applied white box to '70' at (1017, 1706) with size (35, 26)\n",
      "   • Applied white box to '4' at (1044, 1647) with size (20, 25)\n",
      "   • 44 white boxes applied → chase_highres_boxed.png\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 4b: Apply White Boxes Final Output\n",
    "KEEP_CATEGORIES = {\"sensitive_customer\", \"transaction_desc\", \"amount\", \"date\", \"instance\"}\n",
    "NEVER_BLANK = set()\n",
    "\n",
    "def apply_white_boxes(img_path, coord_path):\n",
    "    coords = json.loads(coord_path.read_text())\n",
    "    if not coords:\n",
    "        print(\"Error: No coordinates found in JSON file\")\n",
    "        return None\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    image_width, image_height = img.size\n",
    "\n",
    "    boxes = 0\n",
    "    for c in coords:\n",
    "        cat = c.get(\"category\")\n",
    "        text = c.get(\"text\", \"\").lower()\n",
    "\n",
    "        if cat not in KEEP_CATEGORIES:\n",
    "            continue\n",
    "        if any(kw in text for kw in NEVER_BLANK):\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = map(int, (c[\"x\"], c[\"y\"], c[\"width\"], c[\"height\"]))\n",
    "\n",
    "        inset = 1\n",
    "        x1 = max(0, x + inset)\n",
    "        y1 = max(0, y + inset)\n",
    "        x2 = min(image_width - 1, x + w - inset)\n",
    "        y2 = min(image_height - 1, y + h - inset)\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "\n",
    "        draw.rectangle([x1, y1, x2, y2], fill=\"white\")\n",
    "        boxes += 1\n",
    "        print(f\"   • Applied white box to '{c.get('text', 'unknown')}' at ({x}, {y}) with size ({w}, {h})\")\n",
    "\n",
    "    out = OUTPUT_DIR / f\"{img_path.stem}_boxed.png\"\n",
    "    img.save(out, dpi=(300, 300))\n",
    "    print(f\"   • {boxes} white boxes applied → {out.name}\")\n",
    "    return out\n",
    "\n",
    "def process_white_box_application():\n",
    "    img_path = INPUT_DIR / \"chase_highres.png\"\n",
    "    if not img_path.exists():\n",
    "        img_path = INPUT_DIR / \"chase_highres.jpg\"\n",
    "    if not img_path.exists():\n",
    "        print(f\"Error: Image not found at {img_path}\")\n",
    "        return\n",
    "    coord_path = OUTPUT_DIR / f\"white_box_coords_{img_path.stem}.json\"\n",
    "    if not coord_path.exists():\n",
    "        print(f\"Error: Coordinate file not found at {coord_path}\")\n",
    "        return\n",
    "    print(f\"Processing {img_path.name} for white-box application\")\n",
    "    apply_white_boxes(img_path, coord_path)\n",
    "\n",
    "process_white_box_application()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: PDF Imports & Helpers\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "PDF_INPUT_DIR = Path(\"pdf_inputs\")\n",
    "PDF_OUTPUT_DIR = Path(\"pdf_output_statements\")\n",
    "PDF_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Ensure Poppler is configured for pdf2image\n",
    "# Note: Set the poppler_path if needed, e.g., poppler_path=r\"C:\\path\\to\\poppler\\bin\"\n",
    "\n",
    "# %% Cell 6: PDF Text Extraction\n",
    "def extract_text_from_pdf(pdf_path: Path, page_num: int):\n",
    "    print(f\"   • Extracting text from {pdf_path.name} (page {page_num}) …\", end=\" \", flush=True)\n",
    "    try:\n",
    "        # Convert PDF page to image\n",
    "        images = convert_from_path(pdf_path, first_page=page_num, last_page=page_num, dpi=300)\n",
    "        if not images:\n",
    "            print(\"error: No images extracted from PDF page\")\n",
    "            return []\n",
    "        img = images[0]\n",
    "\n",
    "        # Save temporary image for OCR\n",
    "        temp_img_path = PDF_OUTPUT_DIR / f\"temp_{pdf_path.stem}_page{page_num}.png\"\n",
    "        img.save(temp_img_path, \"PNG\")\n",
    "\n",
    "        # Perform OCR\n",
    "        text = pytesseract.image_to_string(img, config=\"--psm 6 --oem 3\")\n",
    "        tokens = []\n",
    "        current_token = \"\"\n",
    "        for char in text:\n",
    "            if char.isspace():\n",
    "                if current_token:\n",
    "                    tokens.append(current_token)\n",
    "                    current_token = \"\"\n",
    "            elif char in [',', '.', '-'] and current_token and current_token[-1].isdigit():\n",
    "                current_token += char  # Keep commas and periods in numbers\n",
    "            elif char in [',', '.', '-', '/'] and not current_token:\n",
    "                continue  # Skip standalone delimiters\n",
    "            else:\n",
    "                current_token += char\n",
    "        if current_token:\n",
    "            tokens.append(current_token)\n",
    "\n",
    "        extracted = [token.strip() for token in tokens if token.strip()]\n",
    "        print(\"done.\")\n",
    "        print(f\"   • Extracted tokens: {extracted}\")\n",
    "        csv_path = PDF_OUTPUT_DIR / f\"extracted_{pdf_path.stem}_page{page_num}.csv\"\n",
    "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"text\"])\n",
    "            for token in extracted:\n",
    "                writer.writerow([token])\n",
    "        print(f\"   • Saved extracted tokens: {csv_path}\")\n",
    "        return extracted\n",
    "    except Exception as e:\n",
    "        print(f\"error: {type(e).__name__}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_pdf_extract():\n",
    "    pdf_files = list(PDF_INPUT_DIR.glob(\"*.pdf\"))\n",
    "    if not pdf_files:\n",
    "        print(\"⚠️  No PDFs found in\", PDF_INPUT_DIR.resolve())\n",
    "        return\n",
    "    for pdf_path in pdf_files:\n",
    "        print(f\"Processing {pdf_path.name} for text extraction\")\n",
    "        # Get number of pages in PDF\n",
    "        images = convert_from_path(pdf_path, dpi=300)\n",
    "        for page_num in range(len(images)):\n",
    "            extracted = extract_text_from_pdf(pdf_path, page_num + 1)\n",
    "            if not extracted:\n",
    "                print(f\"No text extracted or processing failed for page {page_num + 1}\")\n",
    "            else:\n",
    "                print(f\"Extracted {len(extracted)} text items from page {page_num + 1}\")\n",
    "\n",
    "process_pdf_extract()\n",
    "\n",
    "# %% Cell 7: PDF Coordinate Generation\n",
    "def make_coords_from_pdf(pdf_path: Path, page_num: int):\n",
    "    print(f\"Processing {pdf_path.name} (page {page_num}) for OCR coordinate generation\")\n",
    "    # Convert PDF page to image\n",
    "    images = convert_from_path(pdf_path, first_page=page_num, last_page=page_num, dpi=300)\n",
    "    if not images:\n",
    "        print(\"error: No images extracted from PDF page\")\n",
    "        return []\n",
    "    img = images[0]\n",
    "    temp_img_path = PDF_OUTPUT_DIR / f\"temp_{pdf_path.stem}_page{page_num}.png\"\n",
    "    img.save(temp_img_path, \"PNG\")\n",
    "\n",
    "    words, img_size = ocr_word_boxes(temp_img_path)\n",
    "    coords = []\n",
    "\n",
    "    # 1️⃣ Locate the header “Instances” to determine column boundaries\n",
    "    inst_col = None\n",
    "    header_tokens = {\"instances\", \"instance\", \"lnstances\", \"lntances\"}  # Add common OCR slips\n",
    "    for w in words:\n",
    "        if canon(w[\"text\"]) in header_tokens:\n",
    "            inst_col = (w[\"left\"], w[\"right\"])\n",
    "            break\n",
    "\n",
    "    # 2️⃣ If header not detected, derive column from first instance hit (10, 2, 4, 70)\n",
    "    if inst_col is None:\n",
    "        pending_instance = []\n",
    "        for category, phrase_set in WHITE_BOX_PHRASES.items():\n",
    "            for phrase in phrase_set:\n",
    "                tokens = [canon(tok) for tok in phrase.split()]\n",
    "                n = len(tokens)\n",
    "                i = 0\n",
    "                while i <= len(words) - n:\n",
    "                    slice_txt = [canon(w[\"text\"]) for w in words[i:i+n]]\n",
    "                    if slice_txt == tokens:\n",
    "                        left = min(w[\"left\"] for w in words[i:i+n])\n",
    "                        top = min(w[\"top\"] for w in words[i:i+n])\n",
    "                        right = max(w[\"right\"] for w in words[i:i+n])\n",
    "                        bottom = max(w[\"bottom\"] for w in words[i:i+n])\n",
    "                        coord = {\n",
    "                            \"text\": phrase,\n",
    "                            \"category\": category,\n",
    "                            \"x\": int(left),\n",
    "                            \"y\": int(top),\n",
    "                            \"width\": int(right - left),\n",
    "                            \"height\": int(bottom - top)\n",
    "                        }\n",
    "                        if category == \"instance\":\n",
    "                            pending_instance.append(coord)\n",
    "                        else:\n",
    "                            coords.append(coord)\n",
    "                            print(f\"   • Found “{phrase}” → [{left},{top},{right-left},{bottom-top}]\")\n",
    "                        i += n\n",
    "                    else:\n",
    "                        i += 1\n",
    "        if pending_instance:\n",
    "            xs = [c[\"x\"] for c in pending_instance]\n",
    "            widths = [c[\"width\"] for c in pending_instance]\n",
    "            inst_col = (min(xs), max(x + w for x, w in zip(xs, widths)))\n",
    "            print(f\"   • Instances column derived: {inst_col}\")\n",
    "\n",
    "    # 3️⃣ Apply coordinates, filtering 'instance' hits to the detected column\n",
    "    for category, phrase_set in WHITE_BOX_PHRASES.items():\n",
    "        for phrase in phrase_set:\n",
    "            tokens = [canon(tok) for tok in phrase.split()]\n",
    "            n = len(tokens)\n",
    "            i = 0\n",
    "            while i <= len(words) - n:\n",
    "                slice_txt = [canon(w[\"text\"]) for w in words[i:i+n]]\n",
    "                if slice_txt == tokens:\n",
    "                    left = min(w[\"left\"] for w in words[i:i+n])\n",
    "                    top = min(w[\"top\"] for w in words[i:i+n])\n",
    "                    right = max(w[\"right\"] for w in words[i:i+n])\n",
    "                    bottom = max(w[\"bottom\"] for w in words[i:i+n])\n",
    "\n",
    "                    coord = {\n",
    "                        \"text\": phrase,\n",
    "                        \"category\": category,\n",
    "                        \"x\": int(left),\n",
    "                        \"y\": int(top),\n",
    "                        \"width\": int(right - left),\n",
    "                        \"height\": int(bottom - top)\n",
    "                    }\n",
    "\n",
    "                    if category == \"instance\" and inst_col:\n",
    "                        x_mid = (left + right) // 2\n",
    "                        col_left, col_right = inst_col\n",
    "                        margin = 5  # px slack\n",
    "                        if col_left - margin <= x_mid <= col_right + margin:\n",
    "                            coords.append(coord)\n",
    "                            print(f\"   • Instance boxed “{phrase}” → [{left},{top},{right-left},{bottom-top}]\")\n",
    "                    else:\n",
    "                        coords.append(coord)\n",
    "                        print(f\"   • Found “{phrase}” → [{left},{top},{right-left},{bottom-top}]\")\n",
    "                    i += n\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "    out_json = PDF_OUTPUT_DIR / f\"white_box_coords_{pdf_path.stem}_page{page_num}.json\"\n",
    "    out_json.write_text(json.dumps(coords, indent=2))\n",
    "    print(f\"   • Saved {len(coords)} coords → {out_json.name}\")\n",
    "    return coords\n",
    "\n",
    "def process_pdf_coordinates():\n",
    "    pdf_files = list(PDF_INPUT_DIR.glob(\"*.pdf\"))\n",
    "    if not pdf_files:\n",
    "        print(\"⚠️  No PDFs found in\", PDF_INPUT_DIR.resolve())\n",
    "        return\n",
    "    for pdf_path in pdf_files:\n",
    "        print(f\"Processing {pdf_path.name} for coordinate generation\")\n",
    "        images = convert_from_path(pdf_path, dpi=300)\n",
    "        for page_num in range(len(images)):\n",
    "            make_coords_from_pdf(pdf_path, page_num + 1)\n",
    "\n",
    "process_pdf_coordinates()\n",
    "\n",
    "# %% Cell 8: PDF White Box Application\n",
    "def apply_white_boxes_to_pdf(pdf_path: Path, coord_path: Path):\n",
    "    coords = json.loads(coord_path.read_text())\n",
    "    # Convert PDF page to image\n",
    "    images = convert_from_path(pdf_path, first_page=int(coord_path.stem.split(\"_page\")[-1].split(\".\")[0]),\n",
    "                              last_page=int(coord_path.stem.split(\"_page\")[-1].split(\".\")[0]), dpi=300)\n",
    "    if not images:\n",
    "        print(\"error: No images extracted from PDF page\")\n",
    "        return\n",
    "    img = images[0]\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    image_width, image_height = img.size\n",
    "\n",
    "    boxes = 0\n",
    "    for c in coords:\n",
    "        cat = c.get(\"category\")\n",
    "        text = c.get(\"text\", \"\").lower()\n",
    "\n",
    "        if cat not in KEEP_CATEGORIES:\n",
    "            continue\n",
    "        if any(kw in text for kw in NEVER_BLANK):\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = map(int, (c[\"x\"], c[\"y\"], c[\"width\"], c[\"height\"]))\n",
    "\n",
    "        # ❶ inset by one pixel on each side (min 1 px width / height)\n",
    "        inset = 1\n",
    "        x1 = max(0, x + inset)\n",
    "        y1 = max(0, y + inset)\n",
    "        x2 = min(image_width - 1, x + w - inset)\n",
    "        y2 = min(image_height - 1, y + h - inset)\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue  # too small after inset\n",
    "\n",
    "        draw.rectangle([x1, y1, x2, y2], fill=\"white\")\n",
    "        boxes += 1\n",
    "\n",
    "        print(f\"   • Applied white box to '{c.get('text', 'unknown')}' at ({x}, {y}) with size ({w}, {h})\")\n",
    "\n",
    "    out = PDF_OUTPUT_DIR / f\"{pdf_path.stem}_page{coord_path.stem.split('_page')[-1]}_boxed.png\"\n",
    "    img.save(out, dpi=(300, 300))\n",
    "    print(f\"   • {boxes} white boxes applied → {out.name}\")\n",
    "    return out\n",
    "\n",
    "def process_pdf_redaction():\n",
    "    coord_files = list(PDF_OUTPUT_DIR.glob(\"white_box_coords_*.json\"))\n",
    "    if not coord_files:\n",
    "        print(\"⚠️  No coordinate files found in\", PDF_OUTPUT_DIR.resolve())\n",
    "        return\n",
    "    for coord_path in coord_files:\n",
    "        pdf_path = PDF_INPUT_DIR / f\"{coord_path.stem.replace('white_box_coords_', '').split('_page')[0]}.pdf\"\n",
    "        if pdf_path.exists():\n",
    "            print(f\"Processing {pdf_path.name} for white-box application\")\n",
    "            apply_white_boxes_to_pdf(pdf_path, coord_path)\n",
    "\n",
    "process_pdf_redaction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
