{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import libraries\n",
    "# 2. Image -> OCR, generate a csv with all words\n",
    "# 3. OCR, define specified words with coordinates\n",
    "# 4. Apply white boxes to coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Cell 1 Imports & helpers\n",
    "from pathlib import Path\n",
    "import json, random, time, csv\n",
    "from faker import Faker\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pytesseract\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import ollama\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import difflib\n",
    "import re\n",
    "\n",
    "INPUT_DIR = Path(\"input_images\")\n",
    "OUTPUT_DIR = Path(\"output_statements\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "fake = Faker(\"en_US\")\n",
    "FONT = ImageFont.truetype(\"arial.ttf\", 10)\n",
    "pytesseract.pytesseract.tesseract_cmd = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: Text Extraction\n",
    "def extract_text(img_path: Path):\n",
    "    print(f\"   • Extracting text from {img_path.name} …\", end=\" \", flush=True)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        text = pytesseract.image_to_string(img, config=\"--psm 6 --oem 3\")\n",
    "        # Improved tokenization: preserve numbers with commas and decimals\n",
    "        tokens = []\n",
    "        current_token = \"\"\n",
    "        for char in text:\n",
    "            if char.isspace():\n",
    "                if current_token:\n",
    "                    tokens.append(current_token)\n",
    "                    current_token = \"\"\n",
    "            elif char in [',', '.', '-'] and current_token and current_token[-1].isdigit():\n",
    "                current_token += char  # Keep commas and periods in numbers\n",
    "            elif char in [',', '.', '-', '/'] and not current_token:\n",
    "                continue  # Skip standalone delimiters\n",
    "            else:\n",
    "                current_token += char\n",
    "        if current_token:\n",
    "            tokens.append(current_token)\n",
    "\n",
    "        extracted = [token.strip() for token in tokens if token.strip()]\n",
    "        print(\"done.\")\n",
    "        print(f\"   • Extracted tokens: {extracted}\")\n",
    "        csv_path = OUTPUT_DIR / f\"extracted_{img_path.stem}.csv\"\n",
    "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"text\"])  # Header\n",
    "            for token in extracted:\n",
    "                writer.writerow([token])\n",
    "        print(f\"   • Saved extracted tokens: {csv_path}\")\n",
    "        return extracted\n",
    "    except Exception as e:\n",
    "        print(f\"error: {type(e).__name__}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_folder_extract():\n",
    "    img_files = list(INPUT_DIR.glob(\"*.jp*\")) + list(INPUT_DIR.glob(\"*.png\"))\n",
    "    if not img_files:\n",
    "        print(\"⚠️  No images found in\", INPUT_DIR.resolve())\n",
    "        return\n",
    "    for img in img_files:\n",
    "        print(f\"Processing {img.name} for text extraction\")\n",
    "        extracted = extract_text(img)\n",
    "        if not extracted:\n",
    "            print(\"No text extracted or processing failed\")\n",
    "        else:\n",
    "            print(f\"Extracted {len(extracted)} text items\")\n",
    "\n",
    "process_folder_extract()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 – OCR-driven coordinates using multiple lists\n",
    "\n",
    "from pathlib import Path\n",
    "import json, re\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# ── 1.  Define your individual lists ─────────────────────────────\n",
    "chase_header = {\"JPM organ Chase Bank NA. Ohio/West Virginia Markets pS amas ees\"}\n",
    "\n",
    "date_header  = {\"January 1, 2020 through February 29, 2020\"}\n",
    "\n",
    "account_number     = {\"690783870\"}\n",
    "customer_mailing   = {\"joseph cabrera\", \"miami fl 33161\", \"11020 ne 14th ave\"}\n",
    "\n",
    "checking_summary_instances = {\"10\", \"2\", \"by\", \"70\"}\n",
    "\n",
    "checking_summary_amount = {\n",
    "    \"$81,607.40\", \"125 883.63\", \"- 3,169.04\", \"- 15025.68\", \"$189 296.31\"\n",
    "}\n",
    "\n",
    "deposit_additions_amounts = {\n",
    "    \"$17 120.00\", \"24610.00\", \"ti2408\", \"1349.00\", \"5 000.00\", \"3120.00\",\n",
    "    \"33.138.00\", \"18 114.00\", \"6 908.63\", \"5 100.00\", \"$125883.63\"\n",
    "}\n",
    "deposit_additions_description = {\"deposit\"}\n",
    "deposit_additions_date        = {\n",
    "    \"01/02\", \"01/09\", \"0114\", \"01/15\", \"01/21\",\n",
    "    \"02/21\", \"02/23\", \"02/28\", \"02/29\"\n",
    "}\n",
    "\n",
    "# ── 2.  Bundle them into categories ──────────────────────────────\n",
    "WHITE_BOX_PHRASES: dict[str, set[str]] = {\n",
    "    \"sensitive_customer\": customer_mailing | account_number,\n",
    "    \"transaction_desc\"  : deposit_additions_description,\n",
    "    \"amount\"            : checking_summary_amount | deposit_additions_amounts,\n",
    "    \"date\"              : deposit_additions_date,\n",
    "    \"instance\"          : checking_summary_instances,\n",
    "}\n",
    "\n",
    "# ── utility: word-level OCR boxes ────────────────────────────────\n",
    "def ocr_word_boxes(img_path: Path):\n",
    "    img  = Image.open(img_path).convert(\"RGB\")\n",
    "    data = pytesseract.image_to_data(\n",
    "        img, output_type=pytesseract.Output.DICT, config=\"--psm 6 --oem 3\"\n",
    "    )\n",
    "    words = []\n",
    "    for i, txt in enumerate(data[\"text\"]):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        words.append({\n",
    "            \"text\": txt,\n",
    "            \"left\": data[\"left\"][i],\n",
    "            \"top\":  data[\"top\"][i],\n",
    "            \"right\": data[\"left\"][i] + data[\"width\"][i],\n",
    "            \"bottom\": data[\"top\"][i] + data[\"height\"][i],\n",
    "            \"width\":  data[\"width\"][i],\n",
    "            \"height\": data[\"height\"][i],\n",
    "        })\n",
    "    return words, img.size\n",
    "\n",
    "# helper: canonicalise text for matching\n",
    "def canon(txt: str) -> str:\n",
    "    txt = txt.lower().strip()\n",
    "    txt = re.sub(r'\\s+', ' ', txt)\n",
    "    return txt.replace('$', '').replace(',', '').replace('.', '')\n",
    "\n",
    "# ── main coordinate builder ──────────────────────────────────────\n",
    "def make_coords(img_path: Path):\n",
    "    words, _ = ocr_word_boxes(img_path)\n",
    "    coords   = []\n",
    "\n",
    "    # 1️⃣ locate “Instances” header\n",
    "    inst_col = None\n",
    "    for w in words:\n",
    "        if canon(w[\"text\"]) in {\"instances\", \"instance\", \"lnstances\", \"lntances\"}:\n",
    "            inst_col = (w[\"left\"], w[\"right\"])\n",
    "            break\n",
    "\n",
    "    # 2️⃣ normal matching pass\n",
    "    for category, phrase_set in WHITE_BOX_PHRASES.items():\n",
    "        for phrase in phrase_set:\n",
    "            tokens = [canon(tok) for tok in phrase.split()]\n",
    "            n = len(tokens)\n",
    "            i = 0\n",
    "            while i <= len(words) - n:\n",
    "                if [canon(w[\"text\"]) for w in words[i:i+n]] == tokens:\n",
    "                    left   = min(w[\"left\"]   for w in words[i:i+n])\n",
    "                    top    = min(w[\"top\"]    for w in words[i:i+n])\n",
    "                    right  = max(w[\"right\"]  for w in words[i:i+n])\n",
    "                    bottom = max(w[\"bottom\"] for w in words[i:i+n])\n",
    "\n",
    "                    # filter “instance” hits by column (if header found)\n",
    "                    if category == \"instance\" and inst_col:\n",
    "                        x_mid = (left + right) // 2\n",
    "                        col_left, col_right = inst_col\n",
    "                        margin = 5           # ← original narrow margin\n",
    "                        if not (col_left - margin <= x_mid <= col_right + margin):\n",
    "                            i += 1\n",
    "                            continue\n",
    "\n",
    "                    coords.append({\n",
    "                        \"text\": phrase,\n",
    "                        \"category\": category,\n",
    "                        \"x\": left,\n",
    "                        \"y\": top,\n",
    "                        \"width\":  right - left,\n",
    "                        \"height\": bottom - top,\n",
    "                    })\n",
    "                    print(f\"   • Found “{phrase}” → [{left},{top},{right-left},{bottom-top}]\")\n",
    "                    i += n\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "    out_json = OUTPUT_DIR / f\"white_box_coords_{img_path.stem}.json\"\n",
    "    out_json.write_text(json.dumps(coords, indent=2))\n",
    "    print(f\"   • Saved {len(coords)} coords → {out_json.name}\")\n",
    "    return coords\n",
    "\n",
    "# convenience runner\n",
    "def process_white_box_terms():\n",
    "    img_path = INPUT_DIR / \"chase_highres.png\"\n",
    "    if not img_path.exists():\n",
    "        img_path = INPUT_DIR / \"chase_highres.jpg\"\n",
    "    if not img_path.exists():\n",
    "        print(\"⚠️  chase_highres image not found\"); return\n",
    "\n",
    "    print(f\"Processing {img_path.name} for OCR coordinate generation\")\n",
    "    make_coords(img_path)\n",
    "\n",
    "process_white_box_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Apply White Boxes\n",
    "def apply_white_boxes(img_path, coord_path):\n",
    "    coords = json.loads(coord_path.read_text())\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    image_width, image_height = img.size\n",
    "\n",
    "    boxes = 0\n",
    "    for c in coords:\n",
    "        cat = c.get(\"category\")\n",
    "        text = c.get(\"text\", \"\").lower()\n",
    "\n",
    "        if cat not in KEEP_CATEGORIES:\n",
    "            continue\n",
    "        if any(kw in text for kw in NEVER_BLANK):\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = map(int, (c[\"x\"], c[\"y\"], c[\"width\"], c[\"height\"]))\n",
    "\n",
    "        # ❶ inset by one pixel on each side (min 1 px width / height)\n",
    "        inset = 1\n",
    "        x1 = max(0, x + inset)\n",
    "        y1 = max(0, y + inset)\n",
    "        x2 = min(img.width - 1, x + w - inset)\n",
    "        y2 = min(img.height - 1, y + h - inset)\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue        # too small after inset\n",
    "\n",
    "        draw.rectangle([x1, y1, x2, y2], fill=\"white\")\n",
    "        boxes += 1\n",
    "\n",
    "        print(f\"   • Applied white box to '{c.get('text', 'unknown')}' at ({x}, {y}) with size ({w}, {h})\")\n",
    "\n",
    "    out = OUTPUT_DIR / f\"{img_path.stem}_boxed.png\"\n",
    "    img.save(out, dpi=(300, 300))\n",
    "    print(f\"   • {boxes} white boxes applied → {out.name}\")\n",
    "    return out\n",
    "\n",
    "def process_white_box_application():\n",
    "    img_path = INPUT_DIR / \"chase_highres.png\"\n",
    "    if not img_path.exists():\n",
    "        img_path = INPUT_DIR / \"chase_highres.jpg\"\n",
    "    coord_path = OUTPUT_DIR / f\"white_box_coords_{img_path.stem}.json\"\n",
    "    print(f\"Processing {img_path.name} for white-box application\")\n",
    "    apply_white_boxes(img_path, coord_path)\n",
    "\n",
    "# Note: KEEP_CATEGORIES and NEVER_BLANK should be defined if used in apply_white_boxes\n",
    "# Example: KEEP_CATEGORIES = {\"sensitive_customer\", \"transaction_desc\", \"amount\", \"date\", \"instance\"}\n",
    "# Example: NEVER_BLANK = set()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
